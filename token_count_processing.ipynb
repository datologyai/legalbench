{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ccd69ea-498f-480c-bdab-8b6efb3d8d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/datlitgpt_proto/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-28 03:42:45 __init__.py:183] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 03:42:45,379\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import copy\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from vllm import LLM, SamplingParams\n",
    "import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tasks import TASKS, ISSUE_TASKS\n",
    "from utils import generate_prompts\n",
    "from evaluation import EXACT_MATCH_BALANCED_ACC_TASKS, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7568882-896b-4903-82cd-bc476686e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing = pd.read_json('fp32_saul-7b_evaluation_em-full.jsonl', lines=True)\n",
    "running = pd.read_json('Saul-7B-Base_evaluations.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e004b78-f256-4af6-95ae-c92ec6689295",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat((\n",
    "    running[running.metric_name == 'task_specific'][['metric_name', 'score', 'pred', 'label', 'task']],\n",
    "    existing\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c02e9e8-9675-4748-9621-e73f793c5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_exact_match_tasks = copy.deepcopy(EXACT_MATCH_BALANCED_ACC_TASKS)\n",
    "# It needs a separtate metric\n",
    "index = available_exact_match_tasks.index(\"successor_liability\")\n",
    "del available_exact_match_tasks[index]\n",
    "\n",
    "# This task doesn't even exist\n",
    "index = available_exact_match_tasks.index(\"intra_rule_distinguishing\")\n",
    "del available_exact_match_tasks[index]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "other_tasks = [\n",
    "    'sara_numeric',\n",
    "    'successor_liability',\n",
    "    'citation_prediction_open',\n",
    "    'definition_extraction',\n",
    "    'ssla_company_defendants',\n",
    "    'ssla_individual_defendants',\n",
    "    'ssla_plaintiff',\n",
    "]\n",
    "all_tasks = sorted(other_tasks + available_exact_match_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a42f6f0-bf5e-490b-ab24-3dc503a3363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [03:19<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "token_counts = []\n",
    "\n",
    "for task in tqdm(all_tasks):\n",
    "    with open(f\"tasks/{task}/base_prompt.txt\") as in_file:\n",
    "        prompt_template = in_file.read()\n",
    "\n",
    "    dataset = datasets.load_dataset(\"nguha/legalbench\", task)\n",
    "    test_df = dataset[\"test\"].to_pandas()\n",
    "    answers = test_df[\"answer\"].tolist()\n",
    "    \n",
    "    prompts = generate_prompts(prompt_template=prompt_template, data_df=test_df)\n",
    "    prompt_tokens = [len(tokenizer.encode(text)) for text in prompts]\n",
    "    answer_tokens = [len(tokenizer.encode(answer)) for answer in answers]\n",
    "    full_tokens = [a + b for a, b in zip(prompt_tokens, answer_tokens)]\n",
    "    token_counts.append((task, prompt_tokens, answer_tokens, full_tokens))\n",
    "\n",
    "token_count_df = pd.DataFrame(token_counts, columns=['task', 'num_prompt_tokens', 'num_answer_tokens', 'num_full_tokens'])\n",
    "total.sort_values('task', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cadeb57-03a3-4e9e-9221-3d03942e575a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>num_prompt_tokens</th>\n",
       "      <th>num_answer_tokens</th>\n",
       "      <th>num_full_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sara_numeric</td>\n",
       "      <td>[7892, 7902, 7891, 7892, 7899, 7861, 7915, 786...</td>\n",
       "      <td>[4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>[7896, 7906, 7895, 7897, 7903, 7865, 7919, 787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>successor_liability</td>\n",
       "      <td>[493, 494, 521, 530, 517, 528, 528, 562, 543, ...</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 3, 3, 3, 9, 3, 3, ...</td>\n",
       "      <td>[500, 501, 528, 537, 524, 535, 535, 569, 550, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citation_prediction_open</td>\n",
       "      <td>[196, 178, 208, 184, 200, 182, 179, 208, 232, ...</td>\n",
       "      <td>[9, 13, 14, 6, 7, 7, 14, 9, 16, 13, 10, 20, 13...</td>\n",
       "      <td>[205, 191, 222, 190, 207, 189, 193, 217, 248, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>definition_extraction</td>\n",
       "      <td>[728, 691, 729, 803, 753, 716, 768, 799, 767, ...</td>\n",
       "      <td>[3, 2, 3, 4, 4, 3, 4, 3, 2, 3, 2, 6, 3, 2, 3, ...</td>\n",
       "      <td>[731, 693, 732, 807, 757, 719, 772, 802, 769, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssla_company_defendants</td>\n",
       "      <td>[2052, 1847, 2064, 2077, 2088, 2052, 2101, 202...</td>\n",
       "      <td>[4, 7, 7, 9, 8, 7, 5, 6, 8, 6, 14, 8, 5, 5, 16...</td>\n",
       "      <td>[2056, 1854, 2071, 2086, 2096, 2059, 2106, 203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>telemarketing_sales_rule</td>\n",
       "      <td>[450, 422, 439, 438, 468, 432, 443, 436, 453, ...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[452, 424, 441, 440, 470, 434, 445, 438, 455, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>textualism_tool_dictionaries</td>\n",
       "      <td>[1356, 1312, 1306, 1416, 1307, 1347, 1319, 156...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1358, 1314, 1308, 1418, 1309, 1349, 1321, 156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>textualism_tool_plain</td>\n",
       "      <td>[1273, 871, 866, 924, 1063, 974, 1151, 1012, 9...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[1275, 873, 868, 926, 1065, 976, 1153, 1014, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ucc_v_common_law</td>\n",
       "      <td>[352, 354, 349, 346, 349, 358, 347, 350, 346, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[355, 357, 352, 349, 352, 361, 350, 353, 349, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>unfair_tos</td>\n",
       "      <td>[747, 707, 703, 696, 702, 697, 699, 685, 710, ...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, ...</td>\n",
       "      <td>[749, 709, 705, 698, 704, 699, 701, 687, 712, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             task  \\\n",
       "0                    sara_numeric   \n",
       "1             successor_liability   \n",
       "2        citation_prediction_open   \n",
       "3           definition_extraction   \n",
       "4         ssla_company_defendants   \n",
       "..                            ...   \n",
       "156      telemarketing_sales_rule   \n",
       "157  textualism_tool_dictionaries   \n",
       "158         textualism_tool_plain   \n",
       "159              ucc_v_common_law   \n",
       "160                    unfair_tos   \n",
       "\n",
       "                                     num_prompt_tokens  \\\n",
       "0    [7892, 7902, 7891, 7892, 7899, 7861, 7915, 786...   \n",
       "1    [493, 494, 521, 530, 517, 528, 528, 562, 543, ...   \n",
       "2    [196, 178, 208, 184, 200, 182, 179, 208, 232, ...   \n",
       "3    [728, 691, 729, 803, 753, 716, 768, 799, 767, ...   \n",
       "4    [2052, 1847, 2064, 2077, 2088, 2052, 2101, 202...   \n",
       "..                                                 ...   \n",
       "156  [450, 422, 439, 438, 468, 432, 443, 436, 453, ...   \n",
       "157  [1356, 1312, 1306, 1416, 1307, 1347, 1319, 156...   \n",
       "158  [1273, 871, 866, 924, 1063, 974, 1151, 1012, 9...   \n",
       "159  [352, 354, 349, 346, 349, 358, 347, 350, 346, ...   \n",
       "160  [747, 707, 703, 696, 702, 697, 699, 685, 710, ...   \n",
       "\n",
       "                                     num_answer_tokens  \\\n",
       "0    [4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...   \n",
       "1    [7, 7, 7, 7, 7, 7, 7, 7, 7, 3, 3, 3, 9, 3, 3, ...   \n",
       "2    [9, 13, 14, 6, 7, 7, 14, 9, 16, 13, 10, 20, 13...   \n",
       "3    [3, 2, 3, 4, 4, 3, 4, 3, 2, 3, 2, 6, 3, 2, 3, ...   \n",
       "4    [4, 7, 7, 9, 8, 7, 5, 6, 8, 6, 14, 8, 5, 5, 16...   \n",
       "..                                                 ...   \n",
       "156  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "157  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "158  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "159  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "160  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, ...   \n",
       "\n",
       "                                       num_full_tokens  \n",
       "0    [7896, 7906, 7895, 7897, 7903, 7865, 7919, 787...  \n",
       "1    [500, 501, 528, 537, 524, 535, 535, 569, 550, ...  \n",
       "2    [205, 191, 222, 190, 207, 189, 193, 217, 248, ...  \n",
       "3    [731, 693, 732, 807, 757, 719, 772, 802, 769, ...  \n",
       "4    [2056, 1854, 2071, 2086, 2096, 2059, 2106, 203...  \n",
       "..                                                 ...  \n",
       "156  [452, 424, 441, 440, 470, 434, 445, 438, 455, ...  \n",
       "157  [1358, 1314, 1308, 1418, 1309, 1349, 1321, 156...  \n",
       "158  [1275, 873, 868, 926, 1065, 976, 1153, 1014, 9...  \n",
       "159  [355, 357, 352, 349, 352, 361, 350, 353, 349, ...  \n",
       "160  [749, 709, 705, 698, 704, 699, 701, 687, 712, ...  \n",
       "\n",
       "[161 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82f0a62c-2ba9-40c9-a8fa-82f1fb3d7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(total, token_count_df, on='task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfa99d36-12c6-4244-812f-9951d1748603",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_parquet('fp32_saul-7b_legalbench.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
